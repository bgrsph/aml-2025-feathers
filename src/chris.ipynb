{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d6f03adb",
      "metadata": {},
      "source": [
        "### Feathers in Focus: AML 2025 Kaggle Challenge ðŸª¶\n",
        "### Athina Papatriantafyllou â€¢ Alexandra HolÃ­kovÃ¡ â€¢ BuÄŸra SipahioÄŸlu"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3e0faa0",
      "metadata": {},
      "source": [
        "### Setup Instructions\n",
        "> **Setup Commands (in terminal):**\n",
        "> ```bash\n",
        "> python -m venv venv\n",
        "> source venv/bin/activate\n",
        "> pip install -r requirements.txt\n",
        "> ```\n",
        "> **Download the data and unzip it under \"data/raw\":** https://www.kaggle.com/competitions/aml-2025-feathers-in-focus/data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0792013b",
      "metadata": {},
      "source": [
        "### Import the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a3077e6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-10T21:11:26.671621Z",
          "start_time": "2025-12-10T21:11:00.289661Z"
        }
      },
      "outputs": [],
      "source": [
        "# Import the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from PIL import ImageStat\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.io import decode_image\n",
        "from torch.utils.data import Dataset, WeightedRandomSampler\n",
        "from torchvision.transforms import v2\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import itertools\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4fd940a",
      "metadata": {},
      "source": [
        "### Define the constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7a19ebd",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-10T21:11:38.010798Z",
          "start_time": "2025-12-10T21:11:37.987335Z"
        }
      },
      "outputs": [],
      "source": [
        "# Data path constants \n",
        "DATA_DIR = \"../data/raw\"\n",
        "TRAIN_CSV_PATH = f\"{DATA_DIR}/train_images.csv\"\n",
        "TEST_CSV_PATH = f\"{DATA_DIR}/test_images_path.csv\"\n",
        "CLASS_NAMES_PATH = f\"{DATA_DIR}/class_names.npy\"\n",
        "ATTRIBUTES_PATH = f\"{DATA_DIR}/attributes.npy\"\n",
        "ATTRIBUTES_TXT_PATH = f\"{DATA_DIR}/attributes.txt\"\n",
        "TRAIN_IMAGES_BASE_PATH = f\"{DATA_DIR}/train_images\"\n",
        "TEST_IMAGES_BASE_PATH = f\"{DATA_DIR}/test_images\"\n",
        "\n",
        "# Dataset constants\n",
        "VAL_SPLIT_RATIO = 0.2  # 20% validation 80% test for instance. \n",
        "RANDOM_STATE = 45  # Keep the same random state across runs for reproducibility\n",
        "NUM_CLASSES = 200 # It's given in the Kaggle competition description, so we don't need to count it (yet it's counted in EDA part)\n",
        "\n",
        "# Image transformation constants\n",
        "IMAGE_SIZE = 224  # Final image size after transformations\n",
        "RESIZE_SIZE = 256  # Size before center crop for validation/test\n",
        "RANDOM_CROP_SCALE = (0.7, 1.0)  # RandomResizedCrop scale range\n",
        "HORIZONTAL_FLIP_PROB = 0.5  # RandomHorizontalFlip probability\n",
        "ROTATION_DEGREES = 15  # RandomRotation degrees\n",
        "COLOR_JITTER_BRIGHTNESS = 0.2\n",
        "COLOR_JITTER_CONTRAST = 0.25\n",
        "COLOR_JITTER_SATURATION = 0.25\n",
        "COLOR_JITTER_HUE = 0.15\n",
        "\n",
        "# Normalization constants\n",
        "NORMALIZE_MEAN = [0.485, 0.456, 0.406]\n",
        "NORMALIZE_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Device constants\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "BATCH_SIZE_CPU = 8\n",
        "BATCH_SIZE_GPU = 8\n",
        "BATCH_SIZE_MPS = 8\n",
        "NUM_WORKERS_CPU = 0\n",
        "NUM_WORKERS_GPU = 0\n",
        "NUM_WORKERS_MPS = 0\n",
        "PIN_MEMORY_CPU = False\n",
        "PIN_MEMORY_GPU = True\n",
        "PIN_MEMORY_MPS = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc657c80",
      "metadata": {},
      "source": [
        "### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e5fc63f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-10T21:11:40.441027Z",
          "start_time": "2025-12-10T21:11:40.427656Z"
        }
      },
      "outputs": [],
      "source": [
        "# Load the training and test sets\n",
        "train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
        "test_df = pd.read_csv(TEST_CSV_PATH)\n",
        "class_names = np.load(CLASS_NAMES_PATH, allow_pickle=True).item()\n",
        "\n",
        "# Load attributes\n",
        "attributes = np.load(ATTRIBUTES_PATH, allow_pickle=True)\n",
        "with open(ATTRIBUTES_TXT_PATH, \"r\") as f:\n",
        "    attribute_names = [line.strip().split(' ', 1)[1] for line in f.readlines()]\n",
        "\n",
        "# Print the data summary\n",
        "print(\"Loading the data....\")\n",
        "print(f\"-Train Size: {len(train_df)} \\n-Test Size: {len(test_df)} \\n-Number of Classes: {len(class_names)}\")\n",
        "print(f\"-Attributes: {len(attribute_names)} (shape: {attributes.shape if hasattr(attributes, 'shape') else 'N/A'})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "987f8651",
      "metadata": {},
      "source": [
        "### Explore the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79134fe6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-10T21:11:42.706230Z",
          "start_time": "2025-12-10T21:11:42.428980Z"
        }
      },
      "outputs": [],
      "source": [
        "# Inspect the training set by showing 10 random images\n",
        "print(\"Random images (with their labels)from the training set:\")\n",
        "samples = train_df.sample(10)\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "for ax, (_, row) in zip(axes.flat, samples.iterrows()):\n",
        "    img = Image.open(f\"{TRAIN_IMAGES_BASE_PATH}{row['image_path']}\")\n",
        "    label_name = class_names.get(row['label'], f\"Label: {row['label']}\")\n",
        "    ax.set_title(label_name, fontsize=10)\n",
        "    ax.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95016e5f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-10T21:11:46.083208Z",
          "start_time": "2025-12-10T21:11:45.218729Z"
        }
      },
      "outputs": [],
      "source": [
        "# Check image dimensions in the training set (concise version)\n",
        "sizes = []\n",
        "for p in train_df['image_path']:\n",
        "    sizes.append(Image.open(f\"{TRAIN_IMAGES_BASE_PATH}{p}\").size)\n",
        "widths = [s[0] for s in sizes]\n",
        "heights = [s[1] for s in sizes]\n",
        "print(f\"Checking {len(widths)} images' dimensions: \\n-Width: min={min(widths)}, max={max(widths)}, mean={np.mean(widths):.2f}\\n-Height: min={min(heights)}, max={max(heights)}, mean={np.mean(heights):.2f}\")\n",
        "\n",
        "fig, axs = plt.subplots(1,2,figsize=(10,3))\n",
        "axs[0].hist(widths, bins=20, color='skyblue'), axs[0].set(title='Image Widths', xlabel='Width', ylabel='Freq')\n",
        "axs[1].hist(heights, bins=20, color='salmon'), axs[1].set(title='Image Heights', xlabel='Height', ylabel='Freq')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16008297",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-10T21:11:48.553061Z",
          "start_time": "2025-12-10T21:11:48.546922Z"
        }
      },
      "outputs": [],
      "source": [
        "# Inspect the attributes\n",
        "attributes_df = pd.DataFrame({'Index': range(len(attribute_names)), 'Attribute Name': attribute_names})\n",
        "print(\"Attributes:\")\n",
        "display(attributes_df.head(10))\n",
        "print(f\"Shape of attributes: {attributes.shape}\")\n",
        "print(f\"Number of classes: {attributes.shape[0]}\")\n",
        "print(f\"Number of attributes per class: {attributes.shape[1]}\")\n",
        "print(f\"\\nSample attribute names (first 10):\")\n",
        "for i, name in enumerate(attribute_names[:10]):\n",
        "    print(f\"  {i}: {name}\")\n",
        "\n",
        "# Show attributes for a sample class\n",
        "sample_class_idx = 0\n",
        "sample_class_name = class_names.get(sample_class_idx + 1, f\"Class {sample_class_idx}\")\n",
        "sample_attrs = attributes[sample_class_idx]\n",
        "\n",
        "print(f\"\\nSample: {sample_class_name}\")\n",
        "print(f\"Attributes present (value=1):\")\n",
        "present_attrs = [attribute_names[i] for i in range(len(sample_attrs)) if sample_attrs[i] == 1]\n",
        "print(f\"Total: {len(present_attrs)} out of {len(sample_attrs)}\")\n",
        "print(f\"First 10: {present_attrs[:10]}\")\n",
        "\n",
        "# Visualize attribute distribution\n",
        "attr_counts = attributes.sum(axis=0)\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.hist(attr_counts, bins=30, edgecolor='black')\n",
        "plt.xlabel('Number of classes with this attribute')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Attribute Occurrence Across Classes')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nAttribute Statistics:\")\n",
        "print(f\"Min occurrences: {attr_counts.min()}\")\n",
        "print(f\"Max occurrences: {attr_counts.max()}\")\n",
        "print(f\"Mean occurrences: {attr_counts.mean():.2f}\")\n",
        "print(f\"Std occurrences: {attr_counts.std():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7068da38",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-10T21:11:51.468652Z",
          "start_time": "2025-12-10T21:11:51.262289Z"
        }
      },
      "outputs": [],
      "source": [
        "# Plot the class distribution to inspect the balance\n",
        "class_counts = train_df['label'].value_counts().sort_index()\n",
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "\n",
        "# Show the count for each class\n",
        "ax.bar(range(len(class_counts)), class_counts.values, tick_label=None, edgecolor='k', alpha=0.7)\n",
        "ax.set_xlabel('Class Index')\n",
        "ax.set_ylabel('Number of Images')\n",
        "ax.set_title('Number of Images per Class (All 200 Classes)')\n",
        "ax.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistics\n",
        "print(\"Statistics:\")\n",
        "print(f\"-Number of unique classes: {len(class_names)}\")\n",
        "print(f\"-Average number of images per class: {class_counts.mean():.2f}\")\n",
        "print(f\"-Standard deviation of images per class: {class_counts.std():.2f} (Lower the std, more balanced the dataset)\")\n",
        "print(f\"-Minimum number of images per class: {class_counts.min()}\")\n",
        "print(f\"-Maximum number of images per class: {class_counts.max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b2e2ea8",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-10T21:11:56.124011Z",
          "start_time": "2025-12-10T21:11:54.359854Z"
        }
      },
      "outputs": [],
      "source": [
        "# Check for Corrupted Images\n",
        "\n",
        "# Check Training Set\n",
        "corrupt_counter_train = 0\n",
        "for idx, row in train_df.iterrows():\n",
        "    img_path = f\"{TRAIN_IMAGES_BASE_PATH}{row['image_path']}\"\n",
        "    try:\n",
        "        img = Image.open(img_path)\n",
        "        img.verify()\n",
        "    except Exception:\n",
        "        corrupt_counter_train += 1\n",
        "\n",
        "# Check Test Set\n",
        "corrupt_counter_test = 0\n",
        "for idx, row in test_df.iterrows():\n",
        "    img_path = f\"{TEST_IMAGES_BASE_PATH}{row['image_path']}\"\n",
        "    try:\n",
        "        img = Image.open(img_path)\n",
        "        img.verify()\n",
        "    except Exception:\n",
        "        corrupt_counter_test += 1\n",
        "\n",
        "# Print the results\n",
        "print(f\"Total corrupt images in training set: {corrupt_counter_train}\")\n",
        "print(f\"Total corrupt images in test set: {corrupt_counter_test}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f59bf6b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-10T21:12:06.016935Z",
          "start_time": "2025-12-10T21:11:59.891287Z"
        }
      },
      "outputs": [],
      "source": [
        "# Check the color stats for all training images\n",
        "def get_color_stats(image_path):\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    stat = ImageStat.Stat(img)\n",
        "    brightness = sum(stat.mean) / len(stat.mean)\n",
        "    contrast = sum(stat.stddev) / len(stat.stddev)\n",
        "    saturation = max(stat.mean) - min(stat.mean)\n",
        "    return brightness, contrast, saturation\n",
        "\n",
        "stats = [get_color_stats(f\"{TRAIN_IMAGES_BASE_PATH}{p}\") for p in train_df['image_path']]\n",
        "brightnesses = [s[0] for s in stats]\n",
        "contrasts = [s[1] for s in stats]\n",
        "saturations = [s[2] for s in stats]\n",
        "\n",
        "print(f\"Color Statistics:\")\n",
        "print(f\"- Brightness: mean={np.mean(brightnesses):.2f}, std={np.std(brightnesses):.2f}, range=[{min(brightnesses):.2f}, {max(brightnesses):.2f}]\")\n",
        "print(f\"- Contrast: mean={np.mean(contrasts):.2f}, std={np.std(contrasts):.2f}, range=[{min(contrasts):.2f}, {max(contrasts):.2f}]\")\n",
        "print(f\"- Saturation: mean={np.mean(saturations):.2f}, std={np.std(saturations):.2f}, range=[{min(saturations):.2f}, {max(saturations):.2f}]\")\n",
        "print(\"\\nWISE WORDS FROM THE ML GODS:\")\n",
        "print(\"- High variance values indicate that our images already have diverse properties.\\n- Hence, we don't need to use (high parameters for) ColorJitter.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6eae6a5",
      "metadata": {},
      "source": [
        "### Split the data into training, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8ced734",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-10T21:13:14.159062Z",
          "start_time": "2025-12-10T21:13:14.150802Z"
        }
      },
      "outputs": [],
      "source": [
        "# Extract image paths and labels\n",
        "X = train_df['image_path'].values\n",
        "y = train_df['label'].values       \n",
        "\n",
        "# Look at indices of labels (Y)\n",
        "print(\"Before correction:\")\n",
        "print(\"- y indices min:\", y.min())\n",
        "print(\"- y indices max:\", y.max())\n",
        "\n",
        "# Since the labels start from 1, convert them to 0-indexed\n",
        "y = y - 1\n",
        "\n",
        "print(\"After correction:\")\n",
        "print(\"- y indices min:\", y.min())\n",
        "print(\"- y indices max:\", y.max())\n",
        "\n",
        "# Split the data into training and validation sets (80% train, 20% validation)\n",
        "X_test = test_df['image_path'].values\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, \n",
        "    test_size = VAL_SPLIT_RATIO, \n",
        "    random_state = RANDOM_STATE, # keep the same random state across runs for reproducibility\n",
        "    stratify = y  # Maintains class distribution in both sets\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "571cae33",
      "metadata": {},
      "source": [
        "### Define the transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9ce10d9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-10T21:13:20.399424Z",
          "start_time": "2025-12-10T21:13:20.395816Z"
        }
      },
      "outputs": [],
      "source": [
        "# Transformations for training set\n",
        "transformation_training = v2.Compose([\n",
        "\n",
        "    # Randomly crop to IMAGE_SIZE from a resized area of the image.\n",
        "    # - Scale controls how much of the original image area we keep (tunable via RANDOM_CROP_SCALE).\n",
        "    # - Since feathers require fine details, we keep the scale high.\n",
        "    # - Antialias=True is used to improve the quality of the resized image.\n",
        "    v2.RandomResizedCrop(size=(IMAGE_SIZE, IMAGE_SIZE), scale=RANDOM_CROP_SCALE, antialias=True),\n",
        "    \n",
        "    # Random horizontal flip (tunable via HORIZONTAL_FLIP_PROB)\n",
        "    v2.RandomHorizontalFlip(p=HORIZONTAL_FLIP_PROB), \n",
        "    \n",
        "    # Random rotation (tunable via ROTATION_DEGREES)\n",
        "    v2.RandomRotation(degrees=ROTATION_DEGREES), \n",
        "    \n",
        "    # Color jitter (tunable via COLOR_JITTER constants)\n",
        "    # Kept small since the stats of the training images are already diverse.\n",
        "    # Strong color augmentations can distort the images and make the model more confused.\n",
        "    v2.ColorJitter(\n",
        "        brightness=COLOR_JITTER_BRIGHTNESS, \n",
        "        contrast=COLOR_JITTER_CONTRAST, \n",
        "        saturation=COLOR_JITTER_SATURATION, \n",
        "        hue=COLOR_JITTER_HUE\n",
        "    ), \n",
        "    \n",
        "    # Convert to float32 and scale to [0,1] (also converts to tensor)\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    \n",
        "    # Normalize the image (ImageNet stats for pretrained models, tunable)\n",
        "    v2.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD), \n",
        "])\n",
        "\n",
        "# Transformations for validation set\n",
        "transformation_validation = v2.Compose([\n",
        "    \n",
        "    # Resize to RESIZE_SIZE (no randomness for consistent validation)\n",
        "    v2.Resize(RESIZE_SIZE, antialias=True),\n",
        "\n",
        "    # Center crop to IMAGE_SIZE (matches the training set)\n",
        "    v2.CenterCrop(IMAGE_SIZE),\n",
        "    \n",
        "    # Convert to float32 and scale to [0,1] (also converts to tensor)\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "     \n",
        "    # Normalize the image (must match the training normalization)\n",
        "    v2.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76735f66",
      "metadata": {},
      "source": [
        "### Create Custom Dataset for PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c80e21f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-10T21:13:25.004455Z",
          "start_time": "2025-12-10T21:13:25.001853Z"
        }
      },
      "outputs": [],
      "source": [
        "# Pytorch needs a custom dataset to load and transform the data\n",
        "class FeatherImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, image_labels, transformation=None, target_transformation=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.image_labels = image_labels\n",
        "        self.transformation = transformation\n",
        "        self.target_transformation = target_transformation\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_labels)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        image_path = self.image_paths[i]\n",
        "        image_label = self.image_labels[i]  \n",
        "        image = decode_image(image_path)\n",
        "        if self.transformation:\n",
        "            image = self.transformation(image)\n",
        "        if self.target_transformation:\n",
        "            image_label = self.target_transformation(image_label)\n",
        "        return image, image_label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fca237a",
      "metadata": {},
      "source": [
        "### Create Dataset Instances and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f5ca385",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-10T21:13:29.255752Z",
          "start_time": "2025-12-10T21:13:29.251001Z"
        }
      },
      "outputs": [],
      "source": [
        "# Create dataset instances with transformations\n",
        "# Create custom dataset instance for training set\n",
        "train_dataset = FeatherImageDataset(\n",
        "    image_paths = [TRAIN_IMAGES_BASE_PATH + path for path in X_train],\n",
        "    image_labels = y_train,\n",
        "    transformation = transformation_training\n",
        ")\n",
        "\n",
        "# Create custom dataset instance for validation set\n",
        "val_dataset = FeatherImageDataset(\n",
        "    image_paths = [TRAIN_IMAGES_BASE_PATH + path for path in X_val],\n",
        "    image_labels = y_val,\n",
        "    transformation = transformation_validation\n",
        ")\n",
        "\n",
        "# Check device availability\n",
        "# - If GPU is available, use it\n",
        "# - If MPS is available, use it (GPU supportfor Apple Silicon)\n",
        "# - Otherwise, use CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "if device.type == 'cuda':\n",
        "    batch_size = BATCH_SIZE_GPU\n",
        "    num_workers = NUM_WORKERS_GPU # Set to 0 for Jupyter notebooks as they might fail with too many workers\n",
        "    pin_memory = PIN_MEMORY_GPU  # FYI: Pin memory speeds up the transfer data from CPU RAM to GPU vRAM\n",
        "elif device.type == 'mps':\n",
        "    batch_size = BATCH_SIZE_MPS\n",
        "    num_workers = NUM_WORKERS_MPS\n",
        "    pin_memory = PIN_MEMORY_MPS  # MPS doesn't support pin_memory\n",
        "else:\n",
        "    batch_size = BATCH_SIZE_CPU\n",
        "    num_workers = NUM_WORKERS_CPU\n",
        "    pin_memory = PIN_MEMORY_CPU  # Not needed for CPU (since it's used to speed up the transfer data from CPU RAM to GPU vRAM)\n",
        "\n",
        "# Print the DataLoader configuration\n",
        "print(\"DataLoader configuration:\")\n",
        "print(f\"- Using device: {device}\")\n",
        "print(f\"- Batch size: {batch_size}\")\n",
        "print(f\"- Number of workers: {num_workers} (0 = main process, avoids pickling issues in Jupyter)\")\n",
        "print(f\"- Pin memory: {pin_memory}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80f241b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate sample weights for class-balanced sampling\n",
        "# This addresses class imbalance by oversampling minority classes\n",
        "print(\"Calculating class-balanced sample weights...\")\n",
        "\n",
        "# Count samples per class\n",
        "class_counts = pd.Series(y_train).value_counts().sort_index()\n",
        "\n",
        "# Calculate weights: inverse of class frequency\n",
        "# Less frequent classes get higher weights\n",
        "class_weights = 1.0 / class_counts\n",
        "print(f\"\\nClass weight statistics:\")\n",
        "print(f\"  Min weight: {class_weights.min():.4f} (most common class)\")\n",
        "print(f\"  Max weight: {class_weights.max():.4f} (rarest class)\")\n",
        "print(f\"  Mean weight: {class_weights.mean():.4f}\")\n",
        "\n",
        "# Assign a weight to each sample based on its class\n",
        "sample_weights = [class_weights[label] for label in y_train]\n",
        "\n",
        "# Create WeightedRandomSampler\n",
        "# This will oversample minority classes during training\n",
        "train_sampler = WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True  # Allow oversampling (drawing samples multiple times)\n",
        ")\n",
        "\n",
        "print(f\"\\nClass-balanced sampler created:\")\n",
        "print(f\"  Total samples per epoch: {len(sample_weights)}\")\n",
        "print(f\"  Sampling with replacement: Yes\")\n",
        "print(f\"  Effect: Minority classes will be seen more frequently during training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "842ed001",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create DataLoader for training set with class-balanced sampling\n",
        "# NOTE: sampler and shuffle are mutually exclusive - we use sampler instead of shuffle\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=train_sampler,  # Use weighted sampler for class balance (replaces shuffle=True)\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory\n",
        ")\n",
        "\n",
        "# Create DataLoader for validation set (no sampling - keep original distribution)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,  # Don't shuffle validation data: So that each time we use the validation, it's the same\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory  \n",
        ")\n",
        "\n",
        "# Print the final information\n",
        "print(f\"\\nSetup:\")\n",
        "print(f\"- Train dataset: {len(train_dataset)} samples\")\n",
        "print(f\"- Validation dataset: {len(val_dataset)} samples\")\n",
        "print(f\"- Batch size: {batch_size}\")\n",
        "print(f\"- Training uses class-balanced sampling: Yes âœ“\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "816e9219",
      "metadata": {},
      "source": [
        "### Birdy CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07499eb7",
      "metadata": {},
      "source": [
        "#### Load data, transform etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69af8c05",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the model and training functions\n",
        "from models.birdy_cnn import BirdyCNN\n",
        "from train import train\n",
        "from validate import validate\n",
        "\n",
        "# Define the constants for augmentation\n",
        "IMAGE_SIZE = 224\n",
        "NUM_CLASSES = 200\n",
        "IMAGE_SCALE = (0.8, 1.0)\n",
        "IMAGE_ROTATION = 10\n",
        "IMAGE_BRIGHTNESS = 0.2\n",
        "IMAGE_CONTRAST = 0.2\n",
        "IMAGE_FLIP = 0.5\n",
        "\n",
        "# Define augmented transforms for training\n",
        "transform_aug = v2.Compose([\n",
        "    v2.RandomResizedCrop(size=(IMAGE_SIZE, IMAGE_SIZE), scale=IMAGE_SCALE),\n",
        "    v2.RandomHorizontalFlip(p=IMAGE_FLIP),\n",
        "    v2.RandomRotation(degrees=IMAGE_ROTATION),\n",
        "    v2.ColorJitter(brightness=IMAGE_BRIGHTNESS, contrast=IMAGE_CONTRAST),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD)\n",
        "])\n",
        "\n",
        "# Create training dataset with augmented transforms\n",
        "train_dataset_aug = FeatherImageDataset(\n",
        "    image_paths=[TRAIN_IMAGES_BASE_PATH + path for path in X_train],\n",
        "    image_labels=y_train,\n",
        "    transformation=transform_aug\n",
        ")\n",
        "\n",
        "# Create DataLoader for training with augmentation AND class-balanced sampling\n",
        "# Reuse the same train_sampler we created earlier for class balance\n",
        "train_loader_aug = DataLoader(\n",
        "    train_dataset_aug,\n",
        "    batch_size=batch_size,\n",
        "    sampler=train_sampler,  # Use weighted sampler for class balance (replaces shuffle=True)\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory\n",
        ")\n",
        "\n",
        "print(f\"Augmented training loader created with class-balanced sampling âœ“\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e86985c",
      "metadata": {},
      "source": [
        "#### Run the BIRDY model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02501529",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Initialize the BirdyCNN model\n",
        "# model = BirdyCNN(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES).to(DEVICE)\n",
        "\n",
        "# # Define the loss function and optimizer\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# print(f\"Using device: {DEVICE}\")\n",
        "# print(f\"\\nTraining BirdyCNN with augmented transforms...\")\n",
        "# print(f\"- Training samples: {len(train_dataset_aug)}\")\n",
        "# print(f\"- Validation samples: {len(val_dataset)}\")\n",
        "# print(f\"- Batch size: {batch_size}\")\n",
        "\n",
        "# # Train the model\n",
        "# trained_model = train(\n",
        "#     model=model,\n",
        "#     train_loader=train_loader_aug,\n",
        "#     val_loader=val_loader,\n",
        "#     criterion=criterion,\n",
        "#     optimizer=optimizer,\n",
        "#     device=DEVICE,\n",
        "#     num_epochs=2\n",
        "# )\n",
        "\n",
        "# # Final validation\n",
        "# final_acc = validate(trained_model, val_loader, DEVICE)\n",
        "# print(f\"\\nFinal Validation Accuracy: {final_acc:.4f} ({final_acc*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83f5c955",
      "metadata": {},
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c23b6e9a",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    # Controls the step size during gradient descent. Too high a value can cause instability; too low can slow convergence.\n",
        "    'learning_rate': [1e-4, 3e-4, 1e-3, 3e-3], # --> TO CHRIS: remove the two values from the middle if it's too much computation\n",
        "    'batch_size': [16,32,64], # Influences training stability and convergence speed --> TO CHRIS: remove 32 if it's too much computation\n",
        "    'num_epochs': [20,30], # Determines the number of training epochs\n",
        "    'optimizer': ['adam', 'sgd'], # Determines the optimizer to use\n",
        "    'dropout_rate': [0.0,0.3,0.5], # Dropout rate for regularization --> TO CHRIS: remove 0.3 if it's too much computation\n",
        "    'l2_weight': [1e-5, 1e-2], # L2 regularization weight (weight decay) \n",
        "}\n",
        "\n",
        "\n",
        "# Early stopping patience (set to None to disable early stopping)\n",
        "EARLY_STOPPING_PATIENCE = 5\n",
        "\n",
        "# Store results\n",
        "grid_search_results = []\n",
        "\n",
        "print(f\"Starting Grid Search with Class-Balanced Sampling + Early Stopping...\")\n",
        "print(f\"Early Stopping Patience: {EARLY_STOPPING_PATIENCE} (set to None to disable)\")\n",
        "print(f\"Total combinations: {len(list(itertools.product(*param_grid.values())))}\")\n",
        "print(f\"Parameter grid:\")\n",
        "for key, values in param_grid.items():\n",
        "    print(f\"  {key}: {values}\")\n",
        "print(f\"\\n{'='*80}\\n\")\n",
        "\n",
        "# Iterate through all combinations\n",
        "for idx, params in enumerate(itertools.product(*param_grid.values())):\n",
        "    lr, batch_size_gs, epochs, opt_name, dropout, l2= params\n",
        "    start_time = time.time()\n",
        "    \n",
        "    try:\n",
        "        # Create new data loaders with the current batch size\n",
        "        # Use class-balanced sampling for training loader\n",
        "        train_loader_gs = DataLoader(\n",
        "            train_dataset_aug,\n",
        "            batch_size=batch_size_gs,\n",
        "            sampler=train_sampler,  # Use weighted sampler for class balance (replaces shuffle=True)\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=pin_memory\n",
        "        )\n",
        "        \n",
        "        val_loader_gs = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=batch_size_gs,\n",
        "            shuffle=False,\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=pin_memory\n",
        "        )\n",
        "        \n",
        "        # Initialize a model with current hyperparameters\n",
        "        model_gs = BirdyCNN(\n",
        "            image_size=IMAGE_SIZE, \n",
        "            num_classes=NUM_CLASSES,\n",
        "            dropout_rate=dropout\n",
        "        ).to(DEVICE)\n",
        "        \n",
        "        # Define criterion\n",
        "        criterion_gs = nn.CrossEntropyLoss()\n",
        "        \n",
        "        # Select optimizer with L2 regularization (or weight_decay for Adam Optimizer)\n",
        "        if opt_name == 'adam':\n",
        "            optimizer_gs = torch.optim.Adam(model_gs.parameters(), lr=lr, weight_decay=l2)\n",
        "        elif opt_name == 'sgd':\n",
        "            optimizer_gs = torch.optim.SGD(model_gs.parameters(), lr=lr, momentum=0.9, weight_decay=l2)\n",
        "        \n",
        "        # Train the model with early stopping\n",
        "        print(f\"Training...\")\n",
        "        trained_model_gs = train(\n",
        "            model=model_gs,\n",
        "            train_loader=train_loader_gs,\n",
        "            val_loader=val_loader_gs,\n",
        "            criterion=criterion_gs,\n",
        "            optimizer=optimizer_gs,\n",
        "            device=DEVICE,\n",
        "            num_epochs=epochs,\n",
        "            patience=EARLY_STOPPING_PATIENCE\n",
        "        )\n",
        "        \n",
        "        # Validate\n",
        "        final_val_acc = validate(trained_model_gs, val_loader_gs, DEVICE)\n",
        "        \n",
        "        elapsed_time = time.time() - start_time\n",
        "        \n",
        "        # Store results\n",
        "        result = {\n",
        "            'learning_rate': lr,\n",
        "            'batch_size': batch_size_gs,\n",
        "            'num_epochs': epochs,\n",
        "            'optimizer': opt_name,\n",
        "            'dropout_rate': dropout,\n",
        "            'l2_weight': l2,\n",
        "            'val_accuracy': final_val_acc,\n",
        "            'training_time': elapsed_time\n",
        "        }\n",
        "        grid_search_results.append(result)\n",
        "        \n",
        "        print(f\"  âœ“ Validation Accuracy: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")\n",
        "        print(f\"  âœ“ Training Time: {elapsed_time:.2f}s\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  âœ— Error: {str(e)}\")\n",
        "        result = {\n",
        "            'learning_rate': lr,\n",
        "            'batch_size': batch_size_gs,\n",
        "            'num_epochs': epochs,\n",
        "            'optimizer': opt_name,\n",
        "            'dropout_rate': dropout,\n",
        "            'l2_weight': l2,\n",
        "            'val_accuracy': None,\n",
        "            'training_time': None,\n",
        "            'error': str(e)\n",
        "        }\n",
        "        grid_search_results.append(result)\n",
        "\n",
        "print(f\"\\nGrid Search Completed!\")\n",
        "print(f\"Total experiments: {len(grid_search_results)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e0a1add",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert results to DataFrame for easier analysis\n",
        "results_df = pd.DataFrame(grid_search_results)\n",
        "\n",
        "# Sort by validation accuracy (descending)\n",
        "results_df_sorted = results_df.sort_values('val_accuracy', ascending=False)\n",
        "\n",
        "print(\"Grid Search Results:\")\n",
        "print(results_df_sorted.head(10).to_string(index=False))\n",
        "\n",
        "print(f\"\\nBest Configuration:\")\n",
        "best_result = results_df_sorted.iloc[0]\n",
        "for key, value in best_result.items():\n",
        "    if key == 'val_accuracy' and value is not None:\n",
        "        print(f\"  {key}: {value:.4f} ({value*100:.2f}%)\")\n",
        "    elif key == 'val_loss' and value is not None:\n",
        "        print(f\"  {key}: {value:.4f}\")\n",
        "    elif key == 'training_time' and value is not None:\n",
        "        print(f\"  {key}: {value:.2f}s\")\n",
        "    else:\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "# Display full results DataFrame\n",
        "print(f\"\\n\\nAll Results:\")\n",
        "print(results_df_sorted.to_string(index=False))\n",
        "\n",
        "# Save results to CSV\n",
        "output_path = '../data/grid_search_results.csv'\n",
        "results_df_sorted.to_csv(output_path, index=False)\n",
        "print(f\"Grid search results saved to: {output_path}\")\n",
        "\n",
        "# Display summary statistics\n",
        "print(f\"\\n\\nSummary Statistics:\")\n",
        "print(results_df[['val_accuracy', 'training_time']].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6312ee29",
      "metadata": {},
      "source": [
        "### Apply the best model to test data and export it to kaggle-friendly csv format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "914f311a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the best hyperparameters from grid search results\n",
        "best_result = results_df_sorted.iloc[0]\n",
        "\n",
        "print(\"Training final model with best hyperparameters:\")\n",
        "print(f\"  Learning Rate: {best_result['learning_rate']}\")\n",
        "print(f\"  Batch Size: {int(best_result['batch_size'])}\")\n",
        "print(f\"  Epochs: {int(best_result['num_epochs'])}\")\n",
        "print(f\"  Optimizer: {best_result['optimizer']}\")\n",
        "print(f\"  Dropout Rate: {best_result['dropout_rate']}\")\n",
        "print(f\"  L2 Weight: {best_result['l2_weight']}\")\n",
        "print(f\"  Expected Val Accuracy (from grid search): {best_result['val_accuracy']:.4f} ({best_result['val_accuracy']*100:.2f}%)\")\n",
        "\n",
        "# Extract hyperparameters\n",
        "best_lr = best_result['learning_rate']\n",
        "best_batch_size = int(best_result['batch_size'])\n",
        "best_epochs = int(best_result['num_epochs'])\n",
        "best_optimizer = best_result['optimizer']\n",
        "best_dropout = best_result['dropout_rate']\n",
        "best_l2 = best_result['l2_weight']\n",
        "\n",
        "# Create data loaders with best batch size\n",
        "train_loader_best = DataLoader(\n",
        "    train_dataset_aug,\n",
        "    batch_size=best_batch_size,\n",
        "    sampler=train_sampler,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory\n",
        ")\n",
        "\n",
        "val_loader_best = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=best_batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory\n",
        ")\n",
        "\n",
        "# Initialize model with best hyperparameters\n",
        "best_model = BirdyCNN(\n",
        "    image_size=IMAGE_SIZE,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    dropout_rate=best_dropout\n",
        ").to(DEVICE)\n",
        "\n",
        "# Define criterion\n",
        "criterion_best = nn.CrossEntropyLoss()\n",
        "\n",
        "# Select optimizer with best hyperparameters\n",
        "if best_optimizer == 'adam':\n",
        "    optimizer_best = torch.optim.Adam(best_model.parameters(), lr=best_lr, weight_decay=best_l2)\n",
        "elif best_optimizer == 'sgd':\n",
        "    optimizer_best = torch.optim.SGD(best_model.parameters(), lr=best_lr, momentum=0.9, weight_decay=best_l2)\n",
        "\n",
        "# Train the model\n",
        "print(f\"\\nTraining best model...\")\n",
        "best_model = train(\n",
        "    model=best_model,\n",
        "    train_loader=train_loader_best,\n",
        "    val_loader=val_loader_best,\n",
        "    criterion=criterion_best,\n",
        "    optimizer=optimizer_best,\n",
        "    device=DEVICE,\n",
        "    num_epochs=best_epochs,\n",
        "    patience=EARLY_STOPPING_PATIENCE\n",
        ")\n",
        "\n",
        "# Final validation\n",
        "final_val_acc = validate(best_model, val_loader_best, DEVICE)\n",
        "print(f\"\\nBest model trained successfully!\")\n",
        "print(f\"   Final Validation Accuracy: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "827a66ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "from export import export_model\n",
        "\n",
        "export_model(\n",
        "    model=best_model,                 # Use the best model from grid search\n",
        "    test_df=test_df,                  # DataFrame containing test image paths\n",
        "    test_images_base_path=TEST_IMAGES_BASE_PATH, \n",
        "    transform=transform_aug,          # Use the same transform you defined earlier (or a validation one without augmentation)\n",
        "    device=DEVICE,                    # 'cuda' or 'cpu'\n",
        "    batch_size=32,            \n",
        "    output_path=\"submission_best_model.csv\",# Filename for the Kaggle submission\n",
        "    kaggle_labels_start_at_1=True     # Set to True if class IDs are 1-200, False if 0-199\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53b5e717",
      "metadata": {},
      "source": [
        "### Investigate the grid search results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6290ff7c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>num_epochs</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>dropout_rate</th>\n",
              "      <th>l2_weight</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>training_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.141221</td>\n",
              "      <td>212.063826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.129771</td>\n",
              "      <td>128.838949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.124682</td>\n",
              "      <td>200.549498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.124682</td>\n",
              "      <td>152.475440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.118321</td>\n",
              "      <td>170.112103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.111959</td>\n",
              "      <td>161.957764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.105598</td>\n",
              "      <td>138.346419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.104326</td>\n",
              "      <td>79.925966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.101781</td>\n",
              "      <td>189.619541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.099237</td>\n",
              "      <td>108.276689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.097964</td>\n",
              "      <td>109.369966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.092875</td>\n",
              "      <td>138.337331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.091603</td>\n",
              "      <td>100.431785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.090331</td>\n",
              "      <td>76.410056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.082697</td>\n",
              "      <td>89.550754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.081425</td>\n",
              "      <td>73.103874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.078880</td>\n",
              "      <td>99.077021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.078880</td>\n",
              "      <td>93.136158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.075064</td>\n",
              "      <td>114.661091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.071247</td>\n",
              "      <td>102.236248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.069975</td>\n",
              "      <td>104.930615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.067430</td>\n",
              "      <td>69.941438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.026718</td>\n",
              "      <td>57.525150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.026718</td>\n",
              "      <td>41.757678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.019084</td>\n",
              "      <td>69.841176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.016539</td>\n",
              "      <td>58.335447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.010178</td>\n",
              "      <td>27.590372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.010178</td>\n",
              "      <td>19.814008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.010178</td>\n",
              "      <td>19.838622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.010178</td>\n",
              "      <td>23.712808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.008906</td>\n",
              "      <td>38.598819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.007634</td>\n",
              "      <td>35.240529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.007634</td>\n",
              "      <td>50.651757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.006361</td>\n",
              "      <td>30.331428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.006361</td>\n",
              "      <td>33.999069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.006361</td>\n",
              "      <td>23.733822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.006361</td>\n",
              "      <td>38.684075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.005089</td>\n",
              "      <td>23.820300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.003817</td>\n",
              "      <td>29.155543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.003817</td>\n",
              "      <td>19.911094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.003817</td>\n",
              "      <td>43.417374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.003817</td>\n",
              "      <td>37.009253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.003817</td>\n",
              "      <td>29.145449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.002545</td>\n",
              "      <td>19.862106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.002545</td>\n",
              "      <td>29.129521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.002545</td>\n",
              "      <td>22.866520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.002545</td>\n",
              "      <td>36.938713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.0030</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.001272</td>\n",
              "      <td>20.498950</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    learning_rate  batch_size  num_epochs optimizer  dropout_rate  l2_weight  \\\n",
              "0          0.0030          16          60       sgd           0.3    0.00001   \n",
              "1          0.0001          16          60      adam           0.5    0.00001   \n",
              "2          0.0030          16          60       sgd           0.5    0.01000   \n",
              "3          0.0001          16          60      adam           0.0    0.00001   \n",
              "4          0.0030          16          60       sgd           0.0    0.00001   \n",
              "5          0.0001          64          60      adam           0.5    0.01000   \n",
              "6          0.0001          16          60      adam           0.3    0.00001   \n",
              "7          0.0001          64          60      adam           0.3    0.00001   \n",
              "8          0.0030          16          60       sgd           0.3    0.01000   \n",
              "9          0.0030          16          60       sgd           0.5    0.00001   \n",
              "10         0.0001          64          60      adam           0.3    0.01000   \n",
              "11         0.0001          16          60      adam           0.3    0.01000   \n",
              "12         0.0001          16          60      adam           0.0    0.01000   \n",
              "13         0.0001          64          60      adam           0.0    0.00001   \n",
              "14         0.0030          64          60       sgd           0.3    0.00001   \n",
              "15         0.0001          64          60      adam           0.0    0.01000   \n",
              "16         0.0030          64          60       sgd           0.0    0.00001   \n",
              "17         0.0030          16          60       sgd           0.0    0.01000   \n",
              "18         0.0001          16          60      adam           0.5    0.01000   \n",
              "19         0.0030          64          60       sgd           0.0    0.01000   \n",
              "20         0.0030          64          60       sgd           0.3    0.01000   \n",
              "21         0.0001          64          60      adam           0.5    0.00001   \n",
              "22         0.0030          64          60       sgd           0.5    0.01000   \n",
              "23         0.0030          64          60       sgd           0.5    0.00001   \n",
              "24         0.0001          16          60       sgd           0.0    0.00001   \n",
              "25         0.0001          16          60       sgd           0.3    0.00001   \n",
              "27         0.0001          16          60       sgd           0.0    0.01000   \n",
              "28         0.0001          64          60       sgd           0.5    0.01000   \n",
              "29         0.0001          64          60       sgd           0.3    0.00001   \n",
              "26         0.0001          16          60       sgd           0.5    0.01000   \n",
              "30         0.0001          64          60       sgd           0.5    0.00001   \n",
              "31         0.0001          16          60       sgd           0.5    0.00001   \n",
              "32         0.0001          16          60       sgd           0.3    0.01000   \n",
              "35         0.0030          64          60      adam           0.3    0.01000   \n",
              "36         0.0030          16          60      adam           0.3    0.00001   \n",
              "34         0.0030          64          60      adam           0.5    0.00001   \n",
              "33         0.0030          16          60      adam           0.3    0.01000   \n",
              "37         0.0030          64          60      adam           0.3    0.00001   \n",
              "38         0.0030          16          60      adam           0.0    0.00001   \n",
              "39         0.0001          64          60       sgd           0.0    0.01000   \n",
              "40         0.0030          16          60      adam           0.0    0.01000   \n",
              "41         0.0030          64          60      adam           0.0    0.01000   \n",
              "42         0.0030          16          60      adam           0.5    0.01000   \n",
              "43         0.0001          64          60       sgd           0.0    0.00001   \n",
              "44         0.0030          16          60      adam           0.5    0.00001   \n",
              "45         0.0001          64          60       sgd           0.3    0.01000   \n",
              "46         0.0030          64          60      adam           0.0    0.00001   \n",
              "47         0.0030          64          60      adam           0.5    0.01000   \n",
              "\n",
              "    val_accuracy  training_time  \n",
              "0       0.141221     212.063826  \n",
              "1       0.129771     128.838949  \n",
              "2       0.124682     200.549498  \n",
              "3       0.124682     152.475440  \n",
              "4       0.118321     170.112103  \n",
              "5       0.111959     161.957764  \n",
              "6       0.105598     138.346419  \n",
              "7       0.104326      79.925966  \n",
              "8       0.101781     189.619541  \n",
              "9       0.099237     108.276689  \n",
              "10      0.097964     109.369966  \n",
              "11      0.092875     138.337331  \n",
              "12      0.091603     100.431785  \n",
              "13      0.090331      76.410056  \n",
              "14      0.082697      89.550754  \n",
              "15      0.081425      73.103874  \n",
              "16      0.078880      99.077021  \n",
              "17      0.078880      93.136158  \n",
              "18      0.075064     114.661091  \n",
              "19      0.071247     102.236248  \n",
              "20      0.069975     104.930615  \n",
              "21      0.067430      69.941438  \n",
              "22      0.026718      57.525150  \n",
              "23      0.026718      41.757678  \n",
              "24      0.019084      69.841176  \n",
              "25      0.016539      58.335447  \n",
              "27      0.010178      27.590372  \n",
              "28      0.010178      19.814008  \n",
              "29      0.010178      19.838622  \n",
              "26      0.010178      23.712808  \n",
              "30      0.008906      38.598819  \n",
              "31      0.007634      35.240529  \n",
              "32      0.007634      50.651757  \n",
              "35      0.006361      30.331428  \n",
              "36      0.006361      33.999069  \n",
              "34      0.006361      23.733822  \n",
              "33      0.006361      38.684075  \n",
              "37      0.005089      23.820300  \n",
              "38      0.003817      29.155543  \n",
              "39      0.003817      19.911094  \n",
              "40      0.003817      43.417374  \n",
              "41      0.003817      37.009253  \n",
              "42      0.003817      29.145449  \n",
              "43      0.002545      19.862106  \n",
              "44      0.002545      29.129521  \n",
              "45      0.002545      22.866520  \n",
              "46      0.002545      36.938713  \n",
              "47      0.001272      20.498950  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the grid search results from CSV\n",
        "gs_results = pd.read_csv(\"../data/grid_search_results.csv\")\n",
        "\n",
        "# Display the top 10 results sorted by validation accuracy\n",
        "display(gs_results.sort_values(\"val_accuracy\", ascending=False).head(50))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c7bf873",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
